{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import ChatGroq class where our api key and model is store\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    groq_api_key = #Need to create a API Key from ChatGroq LangChain,\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    ")\n",
    "\n",
    "#to test our model-- goes to groq cloud and will ask our model to get the response\n",
    "# response=llm.invoke(\"Who is father of computer\")\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use web scrapper to get a job role based on user interest and wrap it \n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "#webbaseLoader will extract the data from the link given\n",
    "loader = WebBaseLoader(\"https://www.amazon.jobs/en-gb/jobs/2774960/software-development-manager-shopping-design-tech\")\n",
    "page_contents = loader.load()\n",
    "if page_contents:\n",
    "    page_data = page_contents[-1].page_content\n",
    "    print(page_data)\n",
    "else:\n",
    "    print(\"No data loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt for our LLM which will show the scrapped data and will extract all the details and give response format wise\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### THIS IS THE SCRAPED TEXT FROM WEBSITE:\n",
    "        {page_data}\n",
    "        ### INSTRUCTION:\n",
    "        The scraped text is from the career's page of a website link provided.\n",
    "        Your job is to extract the job postings and return them in JSON format containing the \n",
    "        following keys: `role`, `experience`, `skills` and `description`.\n",
    "        Only return the valid JSON.\n",
    "        ### VALID JSON (NO PREAMBLE):    \n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "#used to form chain which we pass to the LLm\n",
    "extraction_chain = prompt_extract | llm \n",
    "result = extraction_chain.invoke(input={'page_data': page_data})\n",
    "content_type = type(result.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to show the scapped data in JSON format\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "json_data = json_parser.parse(result.content)\n",
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we import our metadata which has all the techstack and dummy links which will be used by LLM to refer for job links\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"my_portfolio.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we upload our data to chromadb \n",
    "import uuid\n",
    "import chromadb\n",
    "\n",
    "#persistentclient will create a db on disk, it will store it\n",
    "client = chromadb.PersistentClient('vectorstore')\n",
    "collection = client.get_or_create_collection(name=\"portfolio\")\n",
    "#if collection does not have count and being created for the first time then we iterate through all the rows. When we exectue vectorstore folder will be created\n",
    "if not collection.count():\n",
    "    for _, row in df.iterrows():\n",
    "        collection.add(documents=row[\"Techstack\"],\n",
    "                       metadatas={\"links\": row[\"Links\"]},\n",
    "                       ids=[str(uuid.uuid4())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = collection.query(query_texts=job['skills'], n_results=2).get('metadatas', [])\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = json_data\n",
    "#extracting only skills\n",
    "job['skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_email = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### JOB DESCRIPTION:\n",
    "        {job_description}\n",
    "        \n",
    "        ### INSTRUCTION:\n",
    "        You are Ryan, a student at The University of Texas at Dallas pursuing master of science in information technology and Management.\n",
    "        Remember you are Ryan, Graduate Student at University of Texas at Dallas. \n",
    "        Also add the most relevant ones from the following links to showcase Ryan's portfolio: {link_list}\n",
    "        Do not provide a preamble and make it short.\n",
    "        ### EMAIL (NO PREAMBLE):\n",
    "        \n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "chain_email = prompt_email | llm\n",
    "response = chain_email.invoke({\"job_description\": str(job), \"link_list\": links})\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
